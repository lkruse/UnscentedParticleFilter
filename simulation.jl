#=
Author: 
    Liam Kruse
Email: 
    lkruse@stanford.edu
simulation.jl:
    A script for running a state estimation task with the Unscented Particle
    Filter, as presented in 
    "Van Der Merwe, R., Doucet, A., De Freitas, N., & Wan, E. (2000). The 
    Unscented Particle Filter. Advances in Neural Information Processing Systems, 13."
=#

##
#*******************************************************************************
# PACKAGES AND SETUP
#*******************************************************************************
using Distributions
using LinearAlgebra
using PGFPlots
using SparseArrays
using StatsBase

include("ukf.jl")

##
#*******************************************************************************
# FUNCTIONS
#*******************************************************************************
function simulate(T, xâ‚€)    
    states =[xâ‚€]; observations = []; 
    sigma = 1; Q = 1
    R = 0.00001^2
    for t = 2:T
        push!(states, my_f(states[t-1], t) + rand(Normal(0, sigma)))
        push!(observations, my_h(states[t-1], t) + rand(Normal(0, 0.00001)))
    end
    return states, observations
end

##
Ïƒ       = 1e-5
T       = 60
Pâ‚€      = 0.75
N       = 200
Q       = 2*(0.75)
R       = 0.1

# Sigma point parameters
Î±_ukf   = 1
Î²       = 0
Îº       = 2

# Rename later?

xâ‚€ = 1.0

xData, yData = simulate(T, xâ‚€)

x = ones(T,N);
P = Pâ‚€ * ones(T,N);
# x_predict = ones(T,N);
xÌ‚ = ones(N)

P_predict = ones(T,N);

#x_mean_predict = ones(T,N);
xÌ„ = ones(N)

y_predict = ones(T,N);
w = ones(T,N)./N;

ð’³ = []; ð’´ = [];
sqrt_matrix = []
likelihood = 0; likelihood_exponent= 0; prior = 0; proposal = 0; prior_exponent = 0; prior_term=0;


states = 1
observations = 1
vNoise = size(Q,2)
wNoise = size(R,2)

noises = vNoise + wNoise

##
d = MvNormal([0.0], R)
for t = 2:T-1
    for i = 1:N
            
        #myN = [Q zeros(vNoise, wNoise); zeros(wNoise, vNoise) R]
        #P_a = [P[t-1,i] zeros(states, noises); zeros(noises, states) myN]
        P_a = P[t-1,i]
        #x_mean_a = [x[t-1,i]; zeros(noises,1)]
        x_mean_a = x[t-1,i]

        #return P_a, x_mean_a
        Î» = 2
        n = length(x_mean_a)
        weights = [Î» / (n + Î»); fill(1/(2(n + Î»)), 2n)]

        xÌ„p, Pp, Sp, Spâ€² = unscented_transform(x_mean_a, P_a, s -> my_f(s, t), Î», weights)

        Pp = Pp + Q
        xÌ„o, Po, So, Soâ€² = unscented_transform(xÌ„p, Pp, s -> my_h(s, t), Î», weights)

        Po = Po + R
        Ppo = sum(w*(s - xÌ„p)*(sâ€² - xÌ„o)' for (w,s,sâ€²) in zip(weights, So, Soâ€²))

        K = Ppo / Po

        #xÌ„ = xÌ„p + K*(o - xÌ„o)
        #P = Pp - K*Po*K'
        o = yData[t]
        #x_temp = xÌ„p + K*(o - xÌ„o)
        #xÌ„[i] = x_temp[1]
        xÌ„[i] = xÌ„p + K*(o - xÌ„o)
        
        #P_temp = Pp - K*Po*K'

        #P_predict[t,i] = P_temp[1]
        P_predict[t,i] = Pp - K*Po*K'

        #=
        xÌ„[i], P_predict[t,i] = UKFilter(x[t-1,i], P[t-1,i], Q, yData[t], R, t, Î±_ukf, Î², Îº)
        =#
        xÌ‚[i] = rand(Normal(xÌ„[i], sqrt(P_predict[t,i])))
    end

    # Evaluate importance weights up to a normalizing constant
    for i = 1:N
        y_predict[t, i] = my_h(xÌ‚[i], t);

        likelihood_exponent = -0.5 * inv(Ïƒ) * ((yData[t] - y_predict[t, i])^2);
        likelihood = 1e-50 + inv(sqrt(Ïƒ)) * exp(likelihood_exponent);
        # Calculate prior
        #=
        prior_exponent = -Î¸*(xÌ‚[i]) - x[t-1, i];
        prior_term = xÌ‚[i] - x[t-1, i]^(Î±);
        prior = prior_term * exp(prior_exponent);
        # prior = (x_term^(k-1)*exp(-x_term/theta))/((theta^k)*gamma(k));
        =#
        #=
        prior_exponent = -Î¸*xÌ‚[i] - x[t-1, i];
        prior_term = xÌ‚[i] - x[t-1, i]^(Î±-1);
        prior = prior_term * exp(prior_exponent);
        =#
        #sigma = 1
        prior_exponent = -0.5 * inv(sigma) * ((xÌ‚[i] - x[t-1, i])^2);
        prior = inv(sqrt(sigma)) * exp(prior_exponent);

        #prior = prior / (2*(Î¸^Î±))

        # prior = (x_term^(k-1)*exp(-x_term/theta))/((theta^k)*gamma(k));
        # Calculate proposal
        proposal_term = inv(sqrt(P_predict[t, i]));
        proposal_exponent = -0.5 * inv(P_predict[t, i]) * ( xÌ‚[i]-xÌ„[i] )^2;
        proposal = proposal_term * exp(proposal_exponent);
        
        # Assign a value to the weight
        w[t, i] = likelihood * prior / proposal;
        #w[t, i] = likelihood
        #w[t, i] = logpdf(d,[yData[t] - y_predict[t, i]])
        #w[t, i] = 0.001*rand()
    end
    ## Normalize weights
    weightSum = sum(w[t, :]);
    w[t, :] = w[t, :] ./ weightSum;

    resampledPoints = sample(1:N, Weights(w[t,:]), N, replace=true)
    
    x[t, :] = xÌ‚[resampledPoints];
    P[t, :] = P[t, resampledPoints];
end

estimated_x_means = mean(x,dims=2)

##
p = Axis([
    PGFPlots.Linear(1:T, estimated_x_means[:], 
            style="blue, thick,mark options={scale=0.6, fill=blue, solid}",legendentry="UPF Estimate"), 
            PGFPlots.Linear(1:T, xData, 
                 style="black, dashed, thick, mark options={scale=0.6,fill=black, solid}", legendentry="True State Value"),

],
style="enlarge x limits=false,grid=both",
ylabel="y", xlabel="time",
title="UPF State Estimation",
        legendPos = "north east",legendStyle="nodes = {scale = 0.75}")
save("upf.pdf", p)

##
Pâ‚€      = Î±/(Î¸^2)
N       = 200
Q       = 2*(0.75)
R       = 0.1

ð±0 = ones(N)

xÌ„0 = [mean(ð±0)]
P0 = cov(ð±0)*I

N = [Q zeros(vNoise, wNoise); zeros(wNoise, vNoise) R]
P0 = [Pâ‚€ zeros(states, noises); zeros(noises, states) N]
xÌ„0 = [mean(ð±0); zeros(noises,1)]

o = yData[1]

Î» = 2
t = 1

##
n = 3

ws = [Î» / (n + Î»); fill(1/(2(n + Î»)), 2n)]

xÌ„p, Pp, Sp, Spâ€² = unscented_transform(xÌ„0, P0, s -> my_f(s, t), Î», ws)
#Pp[1] = Pp[1] + Q
Pp[diagind(Pp)] = [Pp[1] + Q; Q; R]
xÌ„o, Po, So, Soâ€² = unscented_transform(xÌ„p, Pp, s -> my_h(s, t), Î», ws)
Po = Po + R

Ppo = sum(w*(s - xÌ„p)*(sâ€² - xÌ„o)' for (w,s,sâ€²) in zip(ws, So, Soâ€²))

K = Ppo / Po

xÌ„ = xÌ„p + K*(o - xÌ„o)
P = Pp - K*Po*K'